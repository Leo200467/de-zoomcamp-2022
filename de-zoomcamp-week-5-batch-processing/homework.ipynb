{"cells": [{"cell_type": "code", "execution_count": 1, "id": "f39f47db-acdf-4bcd-a817-1394a5d85e30", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "--2022-02-23 01:35:42--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv\nResolving nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)... 52.217.133.17\nConnecting to nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)|52.217.133.17|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 733822658 (700M) [text/csv]\nSaving to: \u2018fhvhv_tripdata_2021-02.csv\u2019\n\nfhvhv_tripdata_2021 100%[===================>] 699.83M  23.8MB/s    in 30s     \n\n2022-02-23 01:36:13 (23.6 MB/s) - \u2018fhvhv_tripdata_2021-02.csv\u2019 saved [733822658/733822658]\n\n"}], "source": "# !wget https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv"}, {"cell_type": "code", "execution_count": 2, "id": "a989a599-f56b-4c4f-a0c6-56312bf9f4cc", "metadata": {}, "outputs": [], "source": "import pyspark\nfrom pyspark.sql import SparkSession"}, {"cell_type": "code", "execution_count": 3, "id": "4153111f-f30e-4129-9d5b-1a959c813962", "metadata": {}, "outputs": [], "source": "spark = SparkSession.builder \\\n        .master(\"local[*]\") \\\n        .appName('test') \\\n        .getOrCreate()"}, {"cell_type": "code", "execution_count": 4, "id": "b71178a6-035d-40d4-8001-a3398625036d", "metadata": {}, "outputs": [], "source": "from pyspark.sql import types"}, {"cell_type": "code", "execution_count": 5, "id": "9ba57533-58d1-4b55-9595-3310a6053b7d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "copyFromLocal: `fhvhv_tripdata_2021-02.csv': File exists\n"}], "source": "!hdfs dfs -copyFromLocal 'fhvhv_tripdata_2021-02.csv'"}, {"cell_type": "code", "execution_count": 6, "id": "684f7d53-8635-476d-900e-3bd28a65e81c", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df = spark.read \\\n    .option(\"header\", \"true\") \\\n    .csv('fhvhv_tripdata_2021-02.csv')"}, {"cell_type": "code", "execution_count": 7, "id": "49100d97-c7ab-4bd5-af1e-f07d75134771", "metadata": {}, "outputs": [{"data": {"text/plain": "[Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime='2021-02-01 00:10:40', dropoff_datetime='2021-02-01 00:21:09', PULocationID='35', DOLocationID='39', SR_Flag=None),\n Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime='2021-02-01 00:27:23', dropoff_datetime='2021-02-01 00:44:01', PULocationID='39', DOLocationID='35', SR_Flag=None),\n Row(hvfhs_license_num='HV0005', dispatching_base_num='B02510', pickup_datetime='2021-02-01 00:28:38', dropoff_datetime='2021-02-01 00:38:27', PULocationID='39', DOLocationID='91', SR_Flag=None),\n Row(hvfhs_license_num='HV0005', dispatching_base_num='B02510', pickup_datetime='2021-02-01 00:43:37', dropoff_datetime='2021-02-01 01:23:20', PULocationID='91', DOLocationID='228', SR_Flag=None),\n Row(hvfhs_license_num='HV0003', dispatching_base_num='B02872', pickup_datetime='2021-02-01 00:08:42', dropoff_datetime='2021-02-01 00:17:57', PULocationID='126', DOLocationID='250', SR_Flag=None)]"}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": "df.head(5)"}, {"cell_type": "code", "execution_count": 8, "id": "a3a7bc80-7bd9-49e8-81f4-14f84076c42d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- hvfhs_license_num: string (nullable = true)\n |-- dispatching_base_num: string (nullable = true)\n |-- pickup_datetime: string (nullable = true)\n |-- dropoff_datetime: string (nullable = true)\n |-- PULocationID: string (nullable = true)\n |-- DOLocationID: string (nullable = true)\n |-- SR_Flag: string (nullable = true)\n\n"}], "source": "df.printSchema()"}, {"cell_type": "code", "execution_count": 51, "id": "a68662c8-ea96-44ef-914e-8e93a47cf580", "metadata": {}, "outputs": [], "source": "schema = types.StructType([\n    types.StructField('hvfhs_license_num', types.StringType(), True),\n    types.StructField('dispatching_base_num', types.StringType(), True),\n    types.StructField('pickup_datetime', types.TimestampType(), True),\n    types.StructField('dropoff_datetime', types.TimestampType(), True),\n    types.StructField('PULocationID', types.IntegerType(), True),\n    types.StructField('DOLocationID', types.IntegerType(), True),\n    types.StructField('SR_Flag', types.StringType(), True)\n])"}, {"cell_type": "code", "execution_count": 52, "id": "2b2b1c05-9a6c-4249-bb8a-0e3c4da2bf7d", "metadata": {}, "outputs": [], "source": "df = spark.read \\\n    .option(\"header\", \"true\") \\\n    .schema(schema) \\\n    .csv('fhvhv_tripdata_2021-02.csv')"}, {"cell_type": "code", "execution_count": 53, "id": "30f9208e-f00d-4183-aff9-602daa85782d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- hvfhs_license_num: string (nullable = true)\n |-- dispatching_base_num: string (nullable = true)\n |-- pickup_datetime: timestamp (nullable = true)\n |-- dropoff_datetime: timestamp (nullable = true)\n |-- PULocationID: integer (nullable = true)\n |-- DOLocationID: integer (nullable = true)\n |-- SR_Flag: string (nullable = true)\n\n"}], "source": "df.printSchema()"}, {"cell_type": "code", "execution_count": 79, "id": "cbaded4c-0978-4387-a47c-b4dced9add4b", "metadata": {}, "outputs": [{"data": {"text/plain": "'3.1.2'"}, "execution_count": 79, "metadata": {}, "output_type": "execute_result"}], "source": "spark.version"}, {"cell_type": "markdown", "id": "1b219623-eb55-4d9a-bb06-a05d031d37bd", "metadata": {}, "source": "'3.1.2'"}, {"cell_type": "code", "execution_count": 54, "id": "acccb337-bd21-4aeb-8081-ac19e24c61ab", "metadata": {}, "outputs": [], "source": "df = df.repartition(24)"}, {"cell_type": "code", "execution_count": 55, "id": "86ee8888-5391-4299-945b-b79ac9dee0fe", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "total 209M\n-rw-r--r-- 1 root root    0 Feb 23 03:12 _SUCCESS\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00000-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00001-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00002-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00003-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00004-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00005-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00006-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00007-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00008-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00009-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00010-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00011-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00012-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00013-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00014-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00015-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00016-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00017-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00018-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00019-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00020-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00021-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00022-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n-rw-r--r-- 1 root root 8.7M Feb 23 03:12 part-00023-64af185b-ea8b-4e14-b061-2917ba39b75b-c000.snappy.parquet\n"}], "source": "!ls -lh fhvhv/2021/02"}, {"cell_type": "markdown", "id": "9c36ba83-609f-4efd-b773-4705c0b16747", "metadata": {}, "source": "total 209M"}, {"cell_type": "code", "execution_count": 69, "id": "32e5bb5f-e348-43ac-ba15-d258e21f941a", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df.write.parquet('fhvhv/2021/02/', mode='overwrite')"}, {"cell_type": "code", "execution_count": 71, "id": "b07a8b98-fdd9-4acc-91a9-e12a0d9e092c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "copyToLocal: `fhvhv/2021/02/_SUCCESS': File exists\n"}], "source": "!hdfs dfs -copyToLocal 'fhvhv'"}, {"cell_type": "code", "execution_count": 72, "id": "f163a8f0-179f-4aac-b4a0-dbdadbe97b64", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df_fhvhv = spark.read.parquet('fhvhv/2021/02/*')"}, {"cell_type": "code", "execution_count": 73, "id": "6f02f659-0398-4292-a6d5-7d553b0f75b0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- hvfhs_license_num: string (nullable = true)\n |-- dispatching_base_num: string (nullable = true)\n |-- pickup_datetime: timestamp (nullable = true)\n |-- dropoff_datetime: timestamp (nullable = true)\n |-- PULocationID: integer (nullable = true)\n |-- DOLocationID: integer (nullable = true)\n |-- SR_Flag: string (nullable = true)\n\n"}], "source": "df_fhvhv.printSchema()"}, {"cell_type": "markdown", "id": "698121b6-f819-4ebb-99d7-b2244ed8d15f", "metadata": {}, "source": "### Question 3. Count records\n\nHow many taxi trips were there on February 15?\n\nConsider only trips that started on February 15."}, {"cell_type": "code", "execution_count": 74, "id": "f64c06ba-f151-466a-9833-034942d3233b", "metadata": {}, "outputs": [], "source": "df_fhvhv.registerTempTable('fhvhv_data')"}, {"cell_type": "code", "execution_count": 75, "id": "5e4daa5b-178d-48b8-87ff-e578d65b808c", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 46:======================================>                   (2 + 1) / 3]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------------------+-----+\n|               date|trips|\n+-------------------+-----+\n|2021-02-15 00:00:00|    5|\n+-------------------+-----+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "spark.sql(\"\"\"\nSELECT\n    date_trunc('day', pickup_datetime) AS date,\n    count(1) AS trips\nFROM\n    fhvhv_data\nWHERE\n    pickup_datetime = '2021-02-15'\nGROUP BY \n    date\n\"\"\").show()"}, {"cell_type": "markdown", "id": "2bbe9527-1184-403e-86cb-a559aefd051e", "metadata": {}, "source": "\n|               date|trips|\n|-------------------|-----|\n|2021-02-15 00:00:00|    5|"}, {"cell_type": "markdown", "id": "47bb296e-f30e-4a21-97ca-cb5078ecb0d1", "metadata": {}, "source": "### Question 4. Longest trip for each day\n\nNow calculate the duration for each trip.\n\nTrip starting on which day was the longest?"}, {"cell_type": "code", "execution_count": 96, "id": "b803a03b-1e99-402e-aea4-59cb7296b6f0", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 91:=============================>                            (2 + 2) / 4]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------------------+------------------------------------+--------+--------------------+\n|    pickup_datetime|date_trunc(second, dropoff_datetime)|interval|          t_interval|\n+-------------------+------------------------------------+--------+--------------------+\n|2021-02-11 13:40:44|                 2021-02-12 10:39:44|   75540| 20 hours 59 minutes|\n|2021-02-17 15:54:53|                 2021-02-18 07:48:34|   57221|15 hours 53 minut...|\n|2021-02-20 12:08:15|                 2021-02-21 00:22:14|   44039|12 hours 13 minut...|\n+-------------------+------------------------------------+--------+--------------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "spark.sql(\"\"\"\nSELECT\n    date_trunc('second', pickup_datetime) AS pickup_datetime,\n    date_trunc('second', dropoff_datetime),\n    INT(TO_UNIX_TIMESTAMP(dropoff_datetime, 'yyyy-mm-dd s-m-h') - TO_UNIX_TIMESTAMP(pickup_datetime, 'yyyy-mm-dd s-m-h')) AS interval,\n    dropoff_datetime - pickup_datetime AS t_interval\nFROM\n    fhvhv_data\nGROUP BY\n    pickup_datetime, dropoff_datetime\nORDER BY\n    3 DESC, 1\nLIMIT\n    3\n\"\"\").show()"}, {"cell_type": "markdown", "id": "37a3e2e2-35e9-4fee-a2da-72b9fbb49d4b", "metadata": {}, "source": "|    pickup_datetime|date_trunc(second, dropoff_datetime)|interval|          t_interval|\n|-------------------|------------------------------------|--------|--------------------|\n|2021-02-11 13:40:44|                 2021-02-12 10:39:44|   75540| 20 hours 59 minutes|\n|2021-02-17 15:54:53|                 2021-02-18 07:48:34|   57221|15 hours 53 minut...|\n|2021-02-20 12:08:15|                 2021-02-21 00:22:14|   44039|12 hours 13 minut...|"}, {"cell_type": "markdown", "id": "b6a7cef0-f1ef-4df4-878d-46f97f966204", "metadata": {}, "source": "### Question 5. Most frequent dispatching_base_num\n\nNow find the most frequently occurring dispatching_base_num in this dataset.\n\nHow many stages this spark job has?\n\nNote: the answer may depend on how you write the query, so there are multiple correct answers. Select the one you have."}, {"cell_type": "code", "execution_count": 99, "id": "68b4d251-bd0c-4205-95a4-6f91ef5ec712", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 103:======================================>                  (2 + 1) / 3]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+-----------+\n|dispatching_base_num|ocurrencies|\n+--------------------+-----------+\n|              B02510|    3233664|\n|              B02764|     965568|\n|              B02872|     882689|\n+--------------------+-----------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "spark.sql(\"\"\"\nSELECT\n    dispatching_base_num,\n    COUNT(1) AS ocurrencies\nFROM\n    fhvhv_data\nGROUP BY\n    dispatching_base_num\nORDER BY\n    ocurrencies DESC\nLIMIT\n    3\n\"\"\").show()"}, {"cell_type": "markdown", "id": "9e66c5fd-2b5e-4627-a0db-58bf8cffb059", "metadata": {}, "source": "[Stage 103:======================================>                  (2 + 1) / 3]\n\n|dispatching_base_num|ocurrencies|\n|--------------------|-----------|\n|              B02510|    3233664|\n|              B02764|     965568|\n|              B02872|     882689|\n|--------------------|-----------|"}, {"cell_type": "markdown", "id": "1ffbe3f2-42ee-4708-bdfd-d8a02c70008e", "metadata": {}, "source": "### Question 6. Most common locations pair\n\nFind the most common pickup-dropoff pair.\n\nFor example:\n\n\"Jamaica Bay / Clinton East\"\n\nEnter two zone names separated by a slash\n\nIf any of the zone names are unknown (missing), use \"Unknown\". For example, \"Unknown / Clinton East\""}, {"cell_type": "code", "execution_count": 101, "id": "0841fd1e-680f-441e-80f3-8ca0e2ff5d31", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "--2022-02-25 01:29:13--  https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\nResolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.165.77\nConnecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.165.77|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 12322 (12K) [application/octet-stream]\nSaving to: \u2018taxi_zone_lookup.csv\u2019\n\ntaxi_zone_lookup.cs 100%[===================>]  12.03K  --.-KB/s    in 0s      \n\n2022-02-25 01:29:13 (88.3 MB/s) - \u2018taxi_zone_lookup.csv\u2019 saved [12322/12322]\n\n"}], "source": "!wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv -O taxi_zone_lookup.csv"}, {"cell_type": "code", "execution_count": 103, "id": "3c34d8e0-1f30-49d5-a0ed-134d909f7060", "metadata": {}, "outputs": [], "source": "!hdfs dfs -copyFromLocal 'taxi_zone_lookup.csv'"}, {"cell_type": "code", "execution_count": 104, "id": "f1c71893-36c2-43b6-b473-6773920c49e1", "metadata": {}, "outputs": [], "source": "df_zone_lookup = spark.read \\\n    .option(\"header\", \"true\") \\\n    .csv('taxi_zone_lookup.csv')"}, {"cell_type": "code", "execution_count": 108, "id": "609e6e6f-0833-4728-963a-b58802388a5e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- LocationID: string (nullable = true)\n |-- Borough: string (nullable = true)\n |-- Zone: string (nullable = true)\n |-- service_zone: string (nullable = true)\n\n"}], "source": "df_zone_lookup.printSchema()"}, {"cell_type": "code", "execution_count": 148, "id": "42aeb87d-1376-4f02-a254-bd765249b740", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- hvfhs_license_num: string (nullable = true)\n |-- dispatching_base_num: string (nullable = true)\n |-- pickup_datetime: timestamp (nullable = true)\n |-- dropoff_datetime: timestamp (nullable = true)\n |-- PULocationID: integer (nullable = true)\n |-- DOLocationID: integer (nullable = true)\n |-- SR_Flag: string (nullable = true)\n\n"}], "source": "df_fhvhv.printSchema()"}, {"cell_type": "code", "execution_count": 154, "id": "da4cc50c-a183-4648-96a0-55328c35e012", "metadata": {}, "outputs": [], "source": "df_zone_lookup.registerTempTable('zone_lookup')"}, {"cell_type": "code", "execution_count": 152, "id": "af1c6648-64e1-42e0-93f6-cb4c59fa6fc7", "metadata": {}, "outputs": [], "source": "df_fhvhv.registerTempTable('fhvhv_data')"}, {"cell_type": "code", "execution_count": 192, "id": "43744fb2-3d88-4875-8f77-6e041f76bda4", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 204:======================================>                  (2 + 1) / 3]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------------------+-------------------+---------------------------------------+-----+\n|pickup_zone_name   |dropzone_name      |location_pair                          |trips|\n+-------------------+-------------------+---------------------------------------+-----+\n|East New York      |East New York      |East New York/East New York            |45041|\n|Borough Park       |Borough Park       |Borough Park/Borough Park              |37329|\n|Canarsie           |Canarsie           |Canarsie/Canarsie                      |28026|\n|Crown Heights North|Crown Heights North|Crown Heights North/Crown Heights North|25976|\n|Bay Ridge          |Bay Ridge          |Bay Ridge/Bay Ridge                    |17934|\n+-------------------+-------------------+---------------------------------------+-----+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "spark.sql(\"\"\"\nSELECT\n    pickup_zone.Zone AS pickup_zone_name,\n    dropoff_zone.Zone AS dropzone_name,\n    CONCAT(pickup_zone.Zone, '/', dropoff_zone.Zone) AS location_pair,\n    COUNT(fhvhv_data.pickup_datetime) AS trips\n\nFROM\n    fhvhv_data \n\nINNER JOIN \n    zone_lookup AS pickup_zone ON \n    fhvhv_data.PULocationID = pickup_zone.LocationID\n\nINNER JOIN \n    zone_lookup AS dropoff_zone ON \n    fhvhv_data.DOLocationID = dropoff_zone.LocationID\n\nGROUP BY\n    2, 1\n\nORDER BY\n    4 DESC\n\n\nLIMIT\n    5\n\"\"\").show(20, False)"}, {"cell_type": "markdown", "id": "53bb454a-cf01-4a4e-8336-dd8dd15c5c77", "metadata": {}, "source": "|pickup_zone_name   |dropzone_name      |location_pair                          |trips|\n|-------------------|-------------------|---------------------------------------|-----|\n|East New York      |East New York      |East New York/East New York            |45041|\n|Borough Park       |Borough Park       |Borough Park/Borough Park              |37329|\n|Canarsie           |Canarsie           |Canarsie/Canarsie                      |28026|\n|Crown Heights North|Crown Heights North|Crown Heights North/Crown Heights North|25976|\n|Bay Ridge          |Bay Ridge          |Bay Ridge/Bay Ridge                    |17934|"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 5}